"""
This script conditions the song lyrics dataset generated by `/scraper/create_dataframes.py` to prepare
it for use in the analysis scripts. It reads parameters for conditioning the data from a config file
(`/analyses/lyrics/preprocess.yaml`). The 'song_darklyrics' column of the data is tokenized using the
custom tokenizer from `/analyses/lyrics/nlp.py`. The table is filtered to remove songs with non-English
lyrics or lyrics that were removed due to copyright claims. To shrink the label space of genres for
analysis, reduced datasets are produced which only contain genres appearing in more than a given
percentage of songs.
"""


import re
import pandas as pd
import yaml
from argparse import ArgumentParser

from nlp import tokenize
import lyrics_utils as utils


MIN_ENGLISH = 0.6  # Songs with lower English word fraction are filtered out. Default is a little higher than 50% to
# include songs with translations, whose lyrics typically include original and translated text


def filter_missing(data):
    """
    Remove songs with missing lyrics
    """
    data = data[~data.song_darklyrics.isnull()]
    data = data[data.song_darklyrics.str.strip().apply(len) > 0]
    return data


def filter_english(data, min_english=MIN_ENGLISH):
    """
    Remove songs that are mostly non-English
    """
    rows = []
    song_words = []
    for i, row in data.iterrows():
        text = row.song_darklyrics.strip()
        words = tokenize(text)
        english_words = tokenize(text, english_only=True)
        is_english = len(english_words) > min_english * len(words)
        if is_english:
            rows.append(i)
            song_words.append(' '.join(english_words))
    print('Non-English songs removed:', len(data) - len(rows))
    data = data.loc[rows]
    data['song_words'] = song_words
    return data


def filter_copyright(data):
    """
    Remove songs that were copyright claimed
    """
    copyrighted = data.song_darklyrics.str.contains(
        'lyrics were removed due to copyright holder\'s request')
    print('Songs with lyrics removed:', len(data[copyrighted]))
    data = data[~copyrighted]
    return data


def create_genre_columns(data):
    """
    Parse 'band_genres' column of data to generate individual genre columns
    """
    band_genres = data.band_genre.drop_duplicates()
    song_genres = data.band_genre
    band_genre_lists = band_genres.str.lower().str.findall('[\w\-]+(?![^(]*\))')
    song_genre_lists = song_genres.str.lower().str.findall('[\w\-]+(?![^(]*\))')
    band_genre_lists = band_genre_lists.apply(lambda x: [s for s in x if s != 'metal'])
    genres = sorted(set(band_genre_lists.sum()))
    cols = [f'genre_{genre}' for genre in genres]
    for genre, col in zip(genres, cols):
        data[col] = song_genre_lists.apply(lambda x: int(genre in x))
    return data, cols


def process_genre(genre):
    """
    Find words (including hyphenated words) not in parentheses
    """
    out = re.findall('[\w\-]+(?![^(]*\))', genre.lower())
    out = [s for s in out if s != 'metal']
    return out


def get_top_genres(data, min_pct):
    """
    Get genre tags appearing in more than min_pct rows of data
    """
    isolated = (data.sum(axis=1) == 1)
    col_pcts = data[isolated].mean(axis=0)
    top_cols = col_pcts.index[col_pcts >= min_pct]
    top_genres = [col.replace('genre_', '') for col in top_cols]
    return top_genres


def reduce_dataset(data, cols, min_pct):
    """
    Reduce genre label space to genres appearing in at least min_pct of rows in data
    """
    top_genres = get_top_genres(data[cols], min_pct)
    out = data.copy()
    drop_cols = [col for col in data.columns if ('genre_' in col) and (col.replace('genre_', '') not in top_genres)]
    out.drop(drop_cols, axis=1, inplace=True)
    return out, top_genres


def ml_dataset(data, genres):
    """
    Generate `pd.DataFrame` with only lyrics and genre columns
    """
    out = pd.DataFrame(index=range(data.shape[0]), columns=['lyrics'] + genres)
    if 'name' in data.columns:
        ref = data['name']
    elif 'band_name' in data.columns and 'song_name' in data.columns:
        ref = data['band_name'] + ' - ' + data['song_name']
        ref.name = 'name'
    else:
        ref = None
    if 'song_darklyrics' in data.columns:
        out['lyrics'] = data['song_darklyrics'].reset_index(drop=True)
    elif 'lyrics' in data.columns:
        out['lyrics'] = data['lyrics']
    out[genres] = data[['genre_' + genre for genre in genres]].reset_index(drop=True)
    return out, ref


def main(config):
    with open(config, 'r') as f:
        cfg = yaml.safe_load(f)
    if 'input' not in cfg.keys():
        raise KeyError(f"missing key 'input' in '{config}'")
    df = pd.read_csv(cfg['input'], low_memory=False)[::100]
    print('Songs:', len(df))
    # Filter data
    print('Filtering songs')
    df = filter_missing(df)
    df = filter_english(df)
    df = filter_copyright(df)
    # Create column for song lengths in seconds
    print('Converting song lengths to seconds')
    df['seconds'] = utils.convert_seconds(df['song_length'])
    print('Creating genre columns')
    df, genre_cols = create_genre_columns(df)
    print('Creating reduced datasets')
    for d in cfg.get('datasets', []):
        if 'min_pct' in d.keys():
            data_type = d.get('type', 'songs')
            if data_type == 'bands':
                print('Combining songs into bands')
                df_out = utils.songs2bands(df)
                print('Bands:', len(df_out))
            else:
                df_out = df.copy()
            df_r, top_genres = reduce_dataset(df_out, genre_cols, d['min_pct'])
            if 'output' in d.keys():
                df_r.to_csv(d['output'], index=False)
            if 'ml-output' in d.keys():
                df_r_ml, df_r_ml_ref = ml_dataset(df_out, top_genres)
                df_r_ml.to_csv(d['ml-output'], index=False)
                if df_r_ml_ref is not None:
                    df_r_ml_ref.to_csv(d['ml-output'].replace('.csv', '-ref.csv'), index=False)
    print('Done')


if __name__ == '__main__':
    parser = ArgumentParser()
    parser.add_argument('config', help='.yaml file of parameters')
    args = parser.parse_args()
    main(args.config)