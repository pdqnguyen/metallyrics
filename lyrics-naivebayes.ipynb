{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-genre classification of heavy metal lyrics - Naive Bayes models\n",
    "\n",
    "This notebook demonstrates the tuning of hyperparameters for a multi-label classification model using Naive Bayes classifiers as the base model for a binary relevance meta-model. See [the parent notebook](./song-lyrics-multi-genre-bow.ipynb) for an in-depth walkthrough of the general problem and the classification framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Imports](#imports)\n",
    "\n",
    "1. [Hyperparamters](#hyperparameters)\n",
    "\n",
    "1. [Evaluation metrics](#metrics)\n",
    "\n",
    "1. [Tuning](#tuning)\n",
    "\n",
    "    * [Multinomial Naive Bayes](#multinomialnb)\n",
    "\n",
    "    * [Complement Multinomial Naive Bayes](#complementnb)\n",
    "\n",
    "    * [Bernoulli Naive Bayes](#bernoullinb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# local imports\n",
    "from multilabel import BinaryRelevance, MultiLabelClassification\n",
    "from nlp import get_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of songs: 60964\n",
      "number of labels: 5\n",
      "labels: ['black', 'death', 'heavy', 'power', 'thrash']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('songs-ml-10pct.csv')\n",
    "X = df.pop('lyrics').values\n",
    "y = df.values\n",
    "genres = df.columns\n",
    "print(f\"number of songs: {X.shape[0]}\")\n",
    "print(f\"number of labels: {y.shape[1]}\")\n",
    "print(f\"labels: {list(genres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9412\n"
     ]
    }
   ],
   "source": [
    "stop_words = get_stopwords()\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tuning'></a>\n",
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='multinomialnb'></a>\n",
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_sets(grid):\n",
    "    first_param = list(grid.keys())[0]\n",
    "    first_values = param_grid.pop(first_param)\n",
    "    out = [{first_param: value} for value in first_values]\n",
    "    for param, values in grid.items():\n",
    "        new = []\n",
    "        prod = itertools.product(range(len(out)), values)\n",
    "        for i, j in prod:\n",
    "            new_dict = out[i].copy()\n",
    "            new_dict.update({param: j})\n",
    "            new.append(new_dict)\n",
    "        out = new\n",
    "    return out\n",
    "\n",
    "def cross_validation(pipeline):\n",
    "    br = BinaryRelevance(pipeline, genres)\n",
    "    mlc = br.cross_validate(X, y, n_splits=3)\n",
    "    mlc.print_report()\n",
    "    auc = mlc.roc_auc_score()\n",
    "    print(auc)\n",
    "    print(\"AUC ROC score = {:.2f} +/- {:.2f}\".format(auc.mean(), auc.std()))\n",
    "    mlc.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vectorizer' : [CountVectorizer, TfidfVectorizer],\n",
    "    'oversampler': [RandomOverSampler, SMOTE],\n",
    "#     'alpha'      : [0.1, 0.5, 1.0],\n",
    "#     'fit_prior'  : [True, False]\n",
    "}\n",
    "results = []\n",
    "param_sets = get_param_sets(param_grid)\n",
    "for i, params in enumerate(param_sets):\n",
    "    print(i)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('vectorizer', params['vectorizer'](stop_words=stop_words)),\n",
    "                ('oversampler', params['oversampler'](random_state=0)),\n",
    "                ('multinomialnb', MultinomialNB())#alpha=params['alpha'], fit_prior=params['fit_prior']))\n",
    "            ]\n",
    "        )\n",
    "        br = BinaryRelevance(pipeline, genres)\n",
    "        mlc = br.cross_validate(X, y, n_splits=3)\n",
    "        results.append((params, mlc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='complementnb'></a>\n",
    "### Complement multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'oversampler': <class 'imblearn.over_sampling._random_over_sampler.RandomOverSampler'>, 'alpha': 0.1, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vectorizer' : [CountVectorizer, TfidfVectorizer],\n",
    "    'oversampler': [RandomOverSampler, SMOTE],\n",
    "    'alpha'      : [0.1, 0.5, 1.0],\n",
    "    'fit_prior'  : [True, False]\n",
    "}\n",
    "for params in get_param_sets(param_grid):\n",
    "    print(params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        cross_validation(\n",
    "            Pipeline(\n",
    "                [\n",
    "                    ('vectorizer', params['vectorizer'](stop_words=stop_words)),\n",
    "                    ('oversampler', params['oversampler'](random_state=0)),\n",
    "                    ('complementnb', ComplementNB(alpha=params['alpha'], fit_prior=params['fit_prior']))\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bernoullinb'></a>\n",
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'oversampler': <class 'imblearn.over_sampling._random_over_sampler.RandomOverSampler'>, 'alpha': 0.1, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vectorizer' : [CountVectorizer, TfidfVectorizer],\n",
    "    'oversampler': [RandomOverSampler, SMOTE],\n",
    "    'alpha'      : [0.1, 0.5, 1.0],\n",
    "    'fit_prior'  : [True, False]\n",
    "}\n",
    "for params in get_param_sets(param_grid):\n",
    "    print(params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        cross_validation(\n",
    "            Pipeline(\n",
    "                [\n",
    "                    ('vectorizer', params['vectorizer'](stop_words=stop_words)),\n",
    "                    ('oversampler', params['oversampler'](random_state=0)),\n",
    "                    ('bernoullinb', BernoulliNB(alpha=params['alpha'], fit_prior=params['fit_prior']))\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metallyrics]",
   "language": "python",
   "name": "conda-env-metallyrics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
